# Basic


<!-- TOC -->

- [Basic](#basic)
    - [思想](#思想)
        - [SGD 的设计很丰满，但现实有些骨感](#sgd-的设计很丰满但现实有些骨感)
    - [参数的更新](#参数的更新)
        - [SGD](#sgd)
            - [将 SGD 实现为类](#将-sgd-实现为类)
            - [SGD 的缺点——梯度方向并不是目的地方向](#sgd-的缺点梯度方向并不是目的地方向)
        - [Momentum](#momentum)
            - [SGD 没有 “动量”](#sgd-没有-动量)
            - [给 SGD 加上 “动量”](#给-sgd-加上-动量)
            - [“动量” 对 $x$ 和 $y$ 两个分量的影响](#动量-对-x-和-y-两个分量的影响)
            - [数学式](#数学式)
            - [Python 实现](#python-实现)
            - [如果函数的形状均向的](#如果函数的形状均向的)
    - [References](#references)

<!-- /TOC -->


## 思想
### SGD 的设计很丰满，但现实有些骨感
1. 要寻找 “谷底”，如果能看到 “谷底” 的方向，那么就可以直接朝着 “谷底” 的方向走就行了。
2. 但现在是看不到 “谷底” 的方向，只能知道当前位置的坡度。所以 SGD 很巧妙的通过不断寻找最陡的方向下降来试图寻找最终的谷底。
3. 粗略的想象，如果我们用很小的步子不断梯度下降，就会知道谷底。但现实是没办法用很小的步子。很小的步子不仅会导致下降的速度过慢，更严重的是会陷入局部极小值。
4. 所以步子不能太小，所以在函数的形状是非均向时，就会出现明显的低效。


## 参数的更新
### SGD
$\boldsymbol{W}\leftarrow\boldsymbol{W}-\eta\frac{\partial L}{\partial\boldsymbol{W}}$

#### 将 SGD 实现为类
1. Python 实现
    ```py
    class SGD:
        def __init__(self, lr=0.01):
            self.lr = lr #  learning rate

        def update(self, params, grads):
            for key in params.keys():
                params[key] -= self.lr * grads[key]
    ```
2. 使用这个 SGD 类，可以按如下方式进行神经网络的参数的更新
    ```py
    network = TwoLayerNet(...)
    optimizer = SGD()

    for i in range(10000):
        ...
        x_batch, t_batch = get_mini_batch(...) # mini-batch
        grads = network.gradient(x_batch, t_batch)
        params = network.params
        optimizer.update(params, grads)
        ...
    ```

#### SGD 的缺点——梯度方向并不是目的地方向
1. 我们来思考一下求下面这个函数的最小值的问题

    $$f(x,y)=\frac{1}{20}x^2+y^2$$

2. 该函数的图像和函数值大小等高线如下图
    <img src="./images/01.png" width="800" style="display: block; margin: 5px 0 10px;" />
3. 可以直观的看出来，在大多数地方，y 的偏导都明显大于 x。通过等高线也能看出来，沿着 y 轴方向变化可以很高效的改变函数值，而沿着 x 轴变化则没那么容易。
4. 如果用图表示梯度的话，则如下图所示
    <img src="./images/02.png" width="600" style="display: block; margin: 5px 0 10px;" />
5. 这个梯度的特征是，在大多数的地方，y 轴方向上梯度大，x 轴方向上梯度小。换句话说，就是 y 轴方向的坡度大，而 x 轴方向的坡度小。
6. 这里需要注意的是，虽然函数的最小值在 $(x, y) = (0, 0)$ 处，但是上图中的梯度在很多地方并没有指向 `(0, 0)`。
7. 这也就是 SGD 的问题：某个位置的梯度只是指向了当前位置函数减小最多的方向，但只是对当前位置而言，而不是整体的目的地而言。
7. 考虑函数图像中高处左侧的一点，当前 y 的梯度是一个比较大的值，而 x 的梯度是一个比较小的值，这类似于在该点所有的两个方向的力。
8. 类似合力的规则，可以知道本次移动在 y 轴方向上移动的比较多，而在 x 轴方向上移动的比较下。也就是说在该点的 "合力" 梯度会指向竖直向下然后稍微向右偏一点点的，因为这个方向的改变会使得本次移动函数值减少最多。但其实如果它够智能，那就应该朝着原点的方向移动，这样才能尽快的到达真正的目的地。
9. 也就是说，每个位置的梯度下降，只是实现了自己眼前的利益最大化，而没有从全局来考虑。
10. 我们来尝试对这个函数应用 SGD。从 $(x, y) = (-7.0, 2.0)$ 处开始搜索，结果如下图所示
    <img src="./images/03.png" width="600" style="display: block; margin: 5px 0 10px;" />
11. SGD 呈 “之” 字形移动，因为这种基本竖直的移动，就是对应当前的梯度，这种移动会导致当前位置函数值变化最大。
12. 想象一个在上图函数图像中移动的样子，就像是在 U 型池里，从左侧偏上的一个点开始放手一个小球，在重力的作用下，以及在这个 U 型池的形状约束下，它会不断的荡来荡去，大部分的运动都是在 y 方向轴上来回往返，但每次在 x 轴方向上只会移动一点点。
13. 也就是说，SGD 的缺点是，如果函数的形状非均向（anisotropic），比如呈延伸状，搜索的路径就会非常低效。
14. 从上图看，其实如果它每次少移动一点，其实反而会更高效，可以粒度更细的确定梯度，而不是像现在这样用一个不高效的梯度一下就走了那么远。不知道有没有针对这种情况的优化。

### Momentum
#### SGD 没有 “动量”
1. 从百度百科看到一句动量的描述：一个物体的动量指的是这个物体在它运动方向上保持运动的趋势。
2. SGD 的梯度下降的距离，是我通过 $\eta\frac{\partial L}{\partial\boldsymbol{W}}$ 指定的，它运动了这么远之后，就立刻停下来，并不会继续滑动知道静止。
3. 也就是说，我命令的下降结束后，它因为没有动量，所以不会保持运动。它不会继续下降，也不会缓缓减速，而是立刻停止。
4. 而这正是 SGD 的特点，按照最陡的方向下降一点，就立刻停止，然后再次寻找当前位置最陡的方向。如果有了动量，那么运动一小段之后继续滑行，滑行的方向大概率就不是最陡的方向了。
5. SGD 就是要尽量沿着每个位置的最陡方向——也就是梯度方向——移动，所以 SGD 不能有动量。
6. 再看前面 U 型池的例子，对于 SGD 的情况，其实滑板并不是在重力的作用下反复运动的，而是在 $\eta\frac{\partial L}{\partial\boldsymbol{W}}$ 的明确命令下。想象成手指滑板更准确，手指滑板中，可以认为重力是不存在的，运动都是由明确的由人指定开始和停止的，动量几乎可以忽略不计。

#### 给 SGD 加上 “动量”
1. 上面说到手指滑板其实也有动量，但几乎可以忽略。Momentum 方法就是在每次梯度下降时，叠加上一个大到不能忽略的 “动量”。
2. 继续想象前面手指滑板 U 型池的情况，假设现在操纵滑板的手指还是按照 SGD 的方式和力量操纵滑板一次次的滑动（梯度下降）。但是，在每次梯度下降的时候，都会加上一个比当前动量小一点的动量。
3. 想象当手指操纵滑板滑到一个最高点时，此时手指将要控制滑板向下（梯度下降），但在此时加上了动量，这个动量有保持滑板继续向上的趋势。但这个动量并不是此时真正的动量大小，而是要小一写，这样这个动量就不会完全抵消手指向下的施力，滑板还是可以掉头进行下一次的梯度下降。
4. 此时滑板仍然会向下（梯度下降），但是因为有了这个反方向的动量，所以这一次梯度下降的作用就被削弱了，就不会下降的那么多。
5. 同样，本次滑动到对面的一个最高点时，又加上了一个基于此时的动量大小担忧小一些的动量。于是下一次的梯度下降的强度又被削弱了。
6. 可以想象，本来这个滑板可以在 U 型池里荡很多下，但因为有了动量的假如，荡不了几下就会停下来。

#### “动量” 对 $x$ 和 $y$ 两个分量的影响
1. 上面分析的动量的影响，是在梯度下降反复变向的情况下的。每次变到反方向时，动量都会给这一次的梯度下降产生一个 “阻力”。按照上面的例子，对于 $y$ 分量，每次梯度下降时，动量都是起到削弱的作用。
2. 那么对于 $x$ 分量，因为每次梯度下降时方向都是相同的，也就是说每次加上的动量都是和梯度下降的方向相同，起到了正向的叠加作用。
3. 所以，引入动量后，会不断抑制 $y$ 方向的下降，同时增强 $x$ 方向的下降。这样，在整体寻找最小值的过程中，之前反复的 $y$ 方向震荡就会很快的逼近 $y$ 轴零点，而之前缓慢的 $x$ 方向移动就会加快。如下图所示
    <img src="./images/04.png" width="600" style="display: block; margin: 5px 0 10px;" />

#### 数学式
$$\boldsymbol{v}\leftarrow\alpha\boldsymbol{v}-\eta\frac{\partial L}{\partial\boldsymbol{W}}$$
$$\boldsymbol{W}\leftarrow\boldsymbol{W}+\boldsymbol{v}$$

1. $\alpha\boldsymbol{v}$ 就是每次加的动量。可以看到，如果不加动量，则梯度下降是和 SGD 一样的。
2. 因为每次梯度下降时的动量都是基于当前 “速度” 的，所以第一个式子是会基于当前的 $\boldsymbol{v}$ 计算下一次梯度下降时的 $\boldsymbol{v}$。
3. 第一次下降时，是从静止开始，$\boldsymbol{v}$ 是 $0$ ，所以只有普通的梯度下降，没有动量。
4. 第二次下降时，$\alpha\boldsymbol{v}-\eta\frac{\partial L}{\partial\boldsymbol{W}}$ 中的 $\boldsymbol{v}$ 就是上一次梯度下降的值。
5. 从方向上来说，对于 $y$ 轴方向，$\boldsymbol{v}$ 和本次将要进行的梯度下降（$-\eta\frac{\partial L}{\partial\boldsymbol{W}}$）方向相反；对于 $x$ 轴方向，两者的方向相同。
6. 从绝对值来说，$\boldsymbol{v}$ 的绝对值要大于 $-\eta\frac{\partial L}{\partial\boldsymbol{W}}$。乘以一个小于 1 的系数 $\alpha$ （设定为 0.9 之类的值）后，会小于 $-\eta\frac{\partial L}{\partial\boldsymbol{W}}$。TODO，代码运行测试。
7. 因此，在 $y$ 轴方向上，因为方向相反，所以会对下一次的梯度下降起到抑制的作用；而在 $x$ 轴方向上，因为方向相同，所以会抑制叠加促进作用。
8. TODO 每次梯度下降本身的下降值都会减小，虽然动量也乘了一个小于一的系数，但有没有可能，梯度下降的值仍然小于这个动量，导致动量比梯度下降更大了？

#### Python 实现
```py
class Momentum:
    def __init__(self, lr=0.01, momentum=0.9):
        self.lr = lr
        self.momentum = momentum
        self.v = None

    def update(self, params, grads):
        if self.v is None:
            self.v = {}
            for key, val in params.items():
                self.v[key] = np.zeros_like(val)

        for key in params.keys():
            self.v[key] = self.momentum*self.v[key] - self.lr*grads[key]
            params[key] += self.v[key]
```


#### 如果函数的形状均向的
1. 可以看到，在函数的形状是非均向时，momentum 的梯度下降比 SGD 效率要好，那如果是均向的呢？
2. 虽然不是很确定，但是看起来，如果是均向的，那么就不会出现在某个轴向上明显的正负震荡的情况。
3. 那么此时在大多数情况下，一个方向上的运动大多数时候要么都是在正方向逼近 0 要么就都是在负方向逼近 0。
4. 因为没有方向变换，所以向量就是起到促进加速的作用的。


## References
* [《深度学习入门》](https://book.douban.com/subject/30270959/)