# Basic


<!-- TOC -->

- [Basic](#basic)
    - [0. 思想](#0-思想)
        - [SGD 的设计很丰满，但现实有些骨感](#sgd-的设计很丰满但现实有些骨感)
    - [1. 参数的更新](#1-参数的更新)
        - [1.1 SGD](#11-sgd)
            - [将 SGD 实现为类](#将-sgd-实现为类)
            - [SGD 的缺点——梯度方向并不是目的地方向](#sgd-的缺点梯度方向并不是目的地方向)
        - [1.2 Momentum](#12-momentum)
            - [SGD 没有 “动量”](#sgd-没有-动量)
            - [给 SGD 加上 “动量”](#给-sgd-加上-动量)
            - [“动量” 对 $x$ 和 $y$ 两个分量的影响](#动量-对-x-和-y-两个分量的影响)
            - [数学式](#数学式)
            - [Python 实现](#python-实现)
            - [如果函数的形状均向的](#如果函数的形状均向的)
        - [1.3 AdaGrad](#13-adagrad)
            - [动态调整学习率](#动态调整学习率)
            - [数学式](#数学式-1)
            - [Python 实现](#python-实现-1)
            - [RMSProp 方法防治 $\boldsymbol{h}$ 减少到 0](#rmsprop-方法防治-\boldsymbolh-减少到-0)
        - [1.4 Adam](#14-adam)
        - [1.5 基于 MNIST 数据集的更新方法的比较](#15-基于-mnist-数据集的更新方法的比较)
    - [2. 权重的初始值](#2-权重的初始值)
        - [2.1 可以将权重初始值设为 0 吗](#21-可以将权重初始值设为-0-吗)
        - [2.2 隐藏层的激活值的分布](#22-隐藏层的激活值的分布)
            - [2.2.1 梯度消失](#221-梯度消失)
            - [2.2.2 “表现力受限”](#222-表现力受限)
            - [2.2.3 Xavier 初始值](#223-xavier-初始值)
                - [`tanh` 函数](#tanh-函数)
    - [References](#references)

<!-- /TOC -->


## 0. 思想
### SGD 的设计很丰满，但现实有些骨感
1. 要寻找 “谷底”，如果能看到 “谷底” 的方向，那么就可以直接朝着 “谷底” 的方向走就行了。
2. 但现在是看不到 “谷底” 的方向，只能知道当前位置的坡度。所以 SGD 很巧妙的通过不断寻找最陡的方向下降来试图寻找最终的谷底。
3. 粗略的想象，如果我们用很小的步子不断梯度下降，就会知道谷底。但现实是没办法用很小的步子。很小的步子不仅会导致下降的速度过慢，更严重的是会陷入局部极小值。
4. 所以步子不能太小，所以在函数的形状是非均向时，就会出现明显的低效。


## 1. 参数的更新
### 1.1 SGD
$\boldsymbol{W}\leftarrow\boldsymbol{W}-\eta\frac{\partial L}{\partial\boldsymbol{W}}$

#### 将 SGD 实现为类
1. Python 实现
    ```py
    class SGD:
        def __init__(self, lr=0.01):
            self.lr = lr #  learning rate

        def update(self, params, grads):
            for key in params.keys():
                params[key] -= self.lr * grads[key]
    ```
2. 使用这个 SGD 类，可以按如下方式进行神经网络的参数的更新
    ```py
    network = TwoLayerNet(...)
    optimizer = SGD()

    for i in range(10000):
        ...
        x_batch, t_batch = get_mini_batch(...) # mini-batch
        grads = network.gradient(x_batch, t_batch)
        params = network.params
        optimizer.update(params, grads)
        ...
    ```

#### SGD 的缺点——梯度方向并不是目的地方向
1. 我们来思考一下求下面这个函数的最小值的问题

    $$f(x,y)=\frac{1}{20}x^2+y^2$$

2. 该函数的图像和函数值大小等高线如下图
    <img src="./images/01.png" width="800" style="display: block; margin: 5px 0 10px;" />
3. 可以直观的看出来，在大多数地方，y 的偏导都明显大于 x。通过等高线也能看出来，沿着 y 轴方向变化可以很高效的改变函数值，而沿着 x 轴变化则没那么容易。
4. 如果用图表示梯度的话，则如下图所示
    <img src="./images/02.png" width="600" style="display: block; margin: 5px 0 10px;" />
5. 这个梯度的特征是，在大多数的地方，y 轴方向上梯度大，x 轴方向上梯度小。换句话说，就是 y 轴方向的坡度大，而 x 轴方向的坡度小。
6. 这里需要注意的是，虽然函数的最小值在 $(x, y) = (0, 0)$ 处，但是上图中的梯度在很多地方并没有指向 `(0, 0)`。
7. 这也就是 SGD 的问题：某个位置的梯度只是指向了当前位置函数减小最多的方向，但只是对当前位置而言，而不是整体的目的地而言。
7. 考虑函数图像中高处左侧的一点，当前 y 的梯度是一个比较大的值，而 x 的梯度是一个比较小的值，这类似于在该点所有的两个方向的力。
8. 类似合力的规则，可以知道本次移动在 y 轴方向上移动的比较多，而在 x 轴方向上移动的比较下。也就是说在该点的 "合力" 梯度会指向竖直向下然后稍微向右偏一点点的，因为这个方向的改变会使得本次移动函数值减少最多。但其实如果它够智能，那就应该朝着原点的方向移动，这样才能尽快的到达真正的目的地。
9. 也就是说，每个位置的梯度下降，只是实现了自己眼前的利益最大化，而没有从全局来考虑。
10. 我们来尝试对这个函数应用 SGD。从 $(x, y) = (-7.0, 2.0)$ 处开始搜索，结果如下图所示
    <img src="./images/03.png" width="600" style="display: block; margin: 5px 0 10px;" />
11. SGD 呈 “之” 字形移动，因为这种基本竖直的移动，就是对应当前的梯度，这种移动会导致当前位置函数值变化最大。
12. 想象一个在上图函数图像中移动的样子，就像是在 U 型池里，从左侧偏上的一个点开始放手一个小球，在重力的作用下，以及在这个 U 型池的形状约束下，它会不断的荡来荡去，大部分的运动都是在 y 方向轴上来回往返，但每次在 x 轴方向上只会移动一点点。
13. 也就是说，SGD 的缺点是，如果函数的形状非均向（anisotropic），比如呈延伸状，搜索的路径就会非常低效。
14. 从上图看，其实如果它每次少移动一点，其实反而会更高效，可以粒度更细的确定梯度，而不是像现在这样用一个不高效的梯度一下就走了那么远。不知道有没有针对这种情况的优化。

### 1.2 Momentum
#### SGD 没有 “动量”
1. 从百度百科看到一句动量的描述：一个物体的动量指的是这个物体在它运动方向上保持运动的趋势。
2. SGD 的梯度下降的距离，是我通过 $\eta\frac{\partial L}{\partial\boldsymbol{W}}$ 指定的，它运动了这么远之后，就立刻停下来，并不会继续滑动知道静止。
3. 也就是说，我命令的下降结束后，它因为没有动量，所以不会保持运动。它不会继续下降，也不会缓缓减速，而是立刻停止。
4. 而这正是 SGD 的特点，按照最陡的方向下降一点，就立刻停止，然后再次寻找当前位置最陡的方向。如果有了动量，那么运动一小段之后继续滑行，滑行的方向大概率就不是最陡的方向了。
5. SGD 就是要尽量沿着每个位置的最陡方向——也就是梯度方向——移动，所以 SGD 不能有动量。
6. 再看前面 U 型池的例子，对于 SGD 的情况，其实滑板并不是在重力的作用下反复运动的，而是在 $\eta\frac{\partial L}{\partial\boldsymbol{W}}$ 的明确命令下。想象成手指滑板更准确，手指滑板中，可以认为重力是不存在的，运动都是由明确的由人指定开始和停止的，动量几乎可以忽略不计。

#### 给 SGD 加上 “动量”
1. 上面说到手指滑板其实也有动量，但几乎可以忽略。Momentum 方法就是在每次梯度下降时，叠加上一个大到不能忽略的 “动量”。
2. 继续想象前面手指滑板 U 型池的情况，假设现在操纵滑板的手指还是按照 SGD 的方式和力量操纵滑板一次次的滑动（梯度下降）。但是，在每次梯度下降的时候，都会加上一个比当前动量小一点的动量。
3. 想象当手指操纵滑板滑到一个最高点时，此时手指将要控制滑板向下（梯度下降），但在此时加上了动量，这个动量有保持滑板继续向上的趋势。但这个动量并不是此时真正的动量大小，而是要小一写，这样这个动量就不会完全抵消手指向下的施力，滑板还是可以掉头进行下一次的梯度下降。
4. 此时滑板仍然会向下（梯度下降），但是因为有了这个反方向的动量，所以这一次梯度下降的作用就被削弱了，就不会下降的那么多。
5. 同样，本次滑动到对面的一个最高点时，又加上了一个基于此时的动量大小担忧小一些的动量。于是下一次的梯度下降的强度又被削弱了。
6. 可以想象，本来这个滑板可以在 U 型池里荡很多下，但因为有了动量的假如，荡不了几下就会停下来。

#### “动量” 对 $x$ 和 $y$ 两个分量的影响
1. 上面分析的动量的影响，是在梯度下降反复变向的情况下的。每次变到反方向时，动量都会给这一次的梯度下降产生一个 “阻力”。按照上面的例子，对于 $y$ 分量，每次梯度下降时，动量都是起到削弱的作用。
2. 那么对于 $x$ 分量，因为每次梯度下降时方向都是相同的，也就是说每次加上的动量都是和梯度下降的方向相同，起到了正向的叠加作用。
3. 所以，引入动量后，会不断抑制 $y$ 方向的下降，同时增强 $x$ 方向的下降。这样，在整体寻找最小值的过程中，之前反复的 $y$ 方向震荡就会很快的逼近 $y$ 轴零点，而之前缓慢的 $x$ 方向移动就会加快。如下图所示
    <img src="./images/04.png" width="600" style="display: block; margin: 5px 0 10px;" />

#### 数学式
$$\boldsymbol{v}\leftarrow\alpha\boldsymbol{v}-\eta\frac{\partial L}{\partial\boldsymbol{W}}$$
$$\boldsymbol{W}\leftarrow\boldsymbol{W}+\boldsymbol{v}$$

1. $\alpha\boldsymbol{v}$ 就是每次加的动量。可以看到，如果不加动量，则梯度下降是和 SGD 一样的。
2. 因为每次梯度下降时的动量都是基于当前 “速度” 的，所以第一个式子是会基于当前的 $\boldsymbol{v}$ 计算下一次梯度下降时的 $\boldsymbol{v}$。
3. 第一次下降时，是从静止开始，$\boldsymbol{v}$ 是 $0$ ，所以只有普通的梯度下降，没有动量。
4. 第二次下降时，$\alpha\boldsymbol{v}-\eta\frac{\partial L}{\partial\boldsymbol{W}}$ 中的 $\boldsymbol{v}$ 就是上一次梯度下降的值。
5. 从方向上来说，对于 $y$ 轴方向，$\boldsymbol{v}$ 和本次将要进行的梯度下降（$-\eta\frac{\partial L}{\partial\boldsymbol{W}}$）方向相反；对于 $x$ 轴方向，两者的方向相同。
6. 从绝对值来说，$\boldsymbol{v}$ 的绝对值要大于 $-\eta\frac{\partial L}{\partial\boldsymbol{W}}$。乘以一个小于 1 的系数 $\alpha$ （设定为 0.9 之类的值）后，会小于 $-\eta\frac{\partial L}{\partial\boldsymbol{W}}$。TODO，代码运行测试。
7. 因此，在 $y$ 轴方向上，因为方向相反，所以会对下一次的梯度下降起到抑制的作用；而在 $x$ 轴方向上，因为方向相同，所以会抑制叠加促进作用。
8. TODO 每次梯度下降本身的下降值都会减小，虽然动量也乘了一个小于一的系数，但有没有可能，梯度下降的值仍然小于这个动量，导致动量比梯度下降更大了？

#### Python 实现
```py
class Momentum:
    def __init__(self, lr=0.01, momentum=0.9):
        self.lr = lr
        self.momentum = momentum
        self.v = None

    def update(self, params, grads):
        if self.v is None:
            self.v = {}
            for key, val in params.items():
                self.v[key] = np.zeros_like(val)

        for key in params.keys():
            self.v[key] = self.momentum*self.v[key] - self.lr*grads[key]
            params[key] += self.v[key]
```


#### 如果函数的形状均向的
1. 可以看到，在函数的形状是非均向时，momentum 的梯度下降比 SGD 效率要好，那如果是均向的呢？
2. 虽然不是很确定，但是看起来，如果是均向的，那么就不会出现在某个轴向上明显的正负震荡的情况。
3. 那么此时在大多数情况下，一个方向上的运动大多数时候要么都是在正方向逼近 0 要么就都是在负方向逼近 0。
4. 因为没有方向变换，所以向量就是起到促进加速的作用的。

### 1.3 AdaGrad
#### 动态调整学习率
1. 在神经网络的学习中，学习率（$η$）的值很重要。学习率过小，会导致学习花费过多时间；反过来，学习率过大，则会导致学习发散而不能正确进行。
2. 在关于学习率的有效技巧中，有一种被称为 **学习率衰减**（learning rate decay）的方法，即随着学习的进行，使学习率逐渐减小。实际上，一开始 “多” 学，然后逐渐 “少” 学的方法，在神经网络的学习中经常被使用。
3. 逐渐减小学习率的想法，相当于将 “全体” 参数的学习率值一起降低。而 **AdaGrad** 进一步发展了这个想法，针对 “一个一个” 的参数，赋予其 “定制” 的值。
4. AdaGrad 会为参数的每个元素适当地调整学习率，与此同时进行学习（AdaGrad 的 Ada 来自英文单词 Adaptive）。

#### 数学式
$$\boldsymbol{h}\leftarrow\boldsymbol{h}+\frac{\partial L}{\partial\boldsymbol{W}}\odot\frac{\partial L}{\partial\boldsymbol{W}}$$
$$\boldsymbol{W}\leftarrow\boldsymbol{W}-\eta\frac{1}{\sqrt{\boldsymbol{h}}}\frac{\partial L}{\partial\boldsymbol{W}}$$

1. 变量 $\boldsymbol{h}$ 保存了以前的所有梯度值的平方和（$\odot$ 表示对应矩阵元素的乘法）。
2. 然后，在更新参数时，通过乘以 $\frac{1}{\sqrt{\boldsymbol{h}}}$，就可以调整学习的尺度。
3. 随着学习的不断进行，$\boldsymbol{h}$ 会越来越大，实际的学习率就会越来越小。
    <img src="./images/05.png" width="600" style="display: block; margin: 5px 0 10px;" />
4. 而且，之前学习率越大的参数，实际学习率减小的就越快。
5. 比如说前面例子的 y 轴参数，开始的时候因为梯度绝对值很大，本来会按照 SGD 那样大幅下降。但因为此时它的 $\boldsymbol{h}$ 也很大，所以就明显削弱了下降效果。
6. 另外还有一点就是，如果某个参数在某个位置时 $\boldsymbol{h}$ 小于 1，那么实际上 $\boldsymbol{h}$ 会增大下一次的学习率。
7. 比如上图第一次下降时，本来 x 轴方向的梯度是小于 1 的，因此如果按照 SGD 只会向右移动一点。但因为此时它的 $\boldsymbol{h}$ 会变成一个明显大于 1 的数，所以向右移动的就比较明显了。

#### Python 实现
```py
class AdaGrad:
    def __init__(self, lr=0.01):
        self.lr = lr
        self.h = None

    def update(self, params, grads):
        if self.h is None:
           self.h = {}
           for key, val in params.items():
               self.h[key] = np.zeros_like(val)

        for key in params.keys():
            self.h[key] += grads[key] * grads[key]
            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)
```

1. 这里需要注意的是，最后一行加上了微小值 `1e-7`。这是为了防止当 `self.h[key]` 中有 0 时，将 0 用作除数的情况。
2. 在很多深度学习的框架中，这个微小值也可以设定为参数。

#### RMSProp 方法防治 $\boldsymbol{h}$ 减少到 0
1. AdaGrad 会记录过去所有梯度的平方和。因此，学习越深入，更新的幅度就越小。实际上，如果无止境地学习，更新量就会变为 0，完全不再更新。
2. 为了改善这个问题，可以使用 RMSProp 方法。RMSProp 方法并不是将过去所有的梯度一视同仁地相加，而是逐渐地遗忘过去的梯度，在做加法运算时将新梯度的信息更多地反映出来。
3. 这种操作从专业上讲，称为 “指数移动平均”，呈指数函数式地减小过去的梯度的尺度。

### 1.4 Adam

### 1.5 基于 MNIST 数据集的更新方法的比较
1. 这个实验以一个 5 层神经网络为对象，其中每层有 100 个神经元。激活函数使用的是 ReLU。
2. 源码在 `./demos/optimizer_compare_mnist.py`。测试代码
    ```py
    # 0:读入MNIST数据==========
    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)

    train_size = x_train.shape[0]
    batch_size = 128
    max_iterations = 2000


    # 1:进行实验的设置==========
    optimizers = {}
    optimizers['SGD'] = SGD()
    optimizers['Momentum'] = Momentum()
    optimizers['AdaGrad'] = AdaGrad()
    optimizers['Adam'] = Adam()
    #optimizers['RMSprop'] = RMSprop()

    networks = {}
    train_loss = {}
    for key in optimizers.keys():
        networks[key] = MultiLayerNet(
            input_size=784, hidden_size_list=[100, 100, 100, 100],
            output_size=10)
        train_loss[key] = []    


    # 2:开始训练==========
    for i in range(max_iterations):
        batch_mask = np.random.choice(train_size, batch_size)
        x_batch = x_train[batch_mask]
        t_batch = t_train[batch_mask]
        
        for key in optimizers.keys():
            grads = networks[key].gradient(x_batch, t_batch)
            optimizers[key].update(networks[key].params, grads)
        
            loss = networks[key].loss(x_batch, t_batch)
            train_loss[key].append(loss)
        
        if i % 100 == 0:
            print( "===========" + "iteration:" + str(i) + "===========")
            for key in optimizers.keys():
                loss = networks[key].loss(x_batch, t_batch)
                print(key + ":" + str(loss))


    # 3.绘制图形==========
    markers = {"SGD": "o", "Momentum": "x", "AdaGrad": "s", "Adam": "D"}
    x = np.arange(max_iterations)
    for key in optimizers.keys():
        plt.plot(x, smooth_curve(train_loss[key]), marker=markers[key], markevery=100, label=key)
    plt.xlabel("iterations")
    plt.ylabel("loss")
    plt.ylim(0, 1)
    plt.legend()
    plt.show()
    ```
3. 输出
    ```sh
    ===========iteration:0===========
    SGD:2.364396210789146
    Momentum:2.4261217609322223
    AdaGrad:2.16233190366153
    Adam:2.1661379304797
    ===========iteration:100===========
    SGD:1.601901336213604
    Momentum:0.33852454157953293
    AdaGrad:0.15668511172030972
    Adam:0.24641438197582696
    ===========iteration:200===========
    SGD:0.7393239598895716
    Momentum:0.17921059986376953
    AdaGrad:0.10122272612654373
    Adam:0.17239291868891393
    ===========iteration:300===========
    SGD:0.5404846036953992
    Momentum:0.16180479904047199
    AdaGrad:0.056495541355878795
    Adam:0.09364112561863941
    ===========iteration:400===========
    SGD:0.402306100952132
    Momentum:0.1509189413549606
    AdaGrad:0.07641001538530545
    Adam:0.12163857898874754
    ===========iteration:500===========
    SGD:0.4880400590934778
    Momentum:0.27585848041696853
    AdaGrad:0.11990903582422144
    Adam:0.18868752650931356
    ===========iteration:600===========
    SGD:0.24947051968119136
    Momentum:0.07308552129379102
    AdaGrad:0.03620177981793199
    Adam:0.03714246759185307
    ===========iteration:700===========
    SGD:0.22857651628931547
    Momentum:0.07979241338942146
    AdaGrad:0.03937541573984139
    Adam:0.039893350873912894
    ===========iteration:800===========
    SGD:0.2605554156718135
    Momentum:0.13450934429900124
    AdaGrad:0.051321940992241785
    Adam:0.05911354829085156
    ===========iteration:900===========
    SGD:0.28081470144087645
    Momentum:0.08644721475741925
    AdaGrad:0.04290114330243809
    Adam:0.0769565489434546
    ===========iteration:1000===========
    SGD:0.22098605072297728
    Momentum:0.07739233872168308
    AdaGrad:0.048948428590088744
    Adam:0.0651119742118878
    ===========iteration:1100===========
    SGD:0.19547780230994916
    Momentum:0.07105618859069646
    AdaGrad:0.05777807847387521
    Adam:0.06458094319080315
    ===========iteration:1200===========
    SGD:0.2076861046482508
    Momentum:0.06838910309773819
    AdaGrad:0.015910327664932965
    Adam:0.05445698620367115
    ===========iteration:1300===========
    SGD:0.2968531021215531
    Momentum:0.1209324520069992
    AdaGrad:0.07006251602589637
    Adam:0.07763953789008499
    ===========iteration:1400===========
    SGD:0.2501930116366662
    Momentum:0.08023199786631298
    AdaGrad:0.030748186319871106
    Adam:0.022148843866858833
    ===========iteration:1500===========
    SGD:0.24713199194592703
    Momentum:0.09090543059097704
    AdaGrad:0.054440722050496895
    Adam:0.061407984164772444
    ===========iteration:1600===========
    SGD:0.22097165571998878
    Momentum:0.052704326085007136
    AdaGrad:0.021394664280808284
    Adam:0.043184760575209466
    ===========iteration:1700===========
    SGD:0.24074511157011802
    Momentum:0.09980322090754362
    AdaGrad:0.06024174907732138
    Adam:0.04353083286248491
    ===========iteration:1800===========
    SGD:0.24732756833521186
    Momentum:0.0811026151474386
    AdaGrad:0.030369929181226964
    Adam:0.036395466746393115
    ===========iteration:1900===========
    SGD:0.24498889914749805
    Momentum:0.125026293687864
    AdaGrad:0.03430576539406276
    Adam:0.0635555903617698
    ```
4. 结果比较
    <img src="./images/06.png" width="1000" style="display: block; margin: 5px 0 10px;" />
5. 上图的结果中可知，与 SGD 相比，其他 3 种方法学习得更快，而且速度基本相同，仔细看的话，AdaGrad 的学习进行得稍微快一点。
6. 这个实验需要注意的地方是，实验结果会随学习率等超参数、神经网络的结构（几层深等）的不同而发生变化。不过，一般而言，与 SGD 相比，其他 3 种方法可以学习得更快，有时最终的识别精度也更高。


## 2. 权重的初始值
### 2.1 可以将权重初始值设为 0 吗
1. 后面我们会介绍抑制过拟合、提高泛化能力的技巧——权值衰减（weight decay）。简单地说，权值衰减就是一种以减小权重参数的值为目的进行学习的方法。通过减小权重参数的值来抑制过拟合的发生。
2. 如果想减小权重的值，一开始就将初始值设为较小的值才是正途。那么如果我们把权重初始值全部设为 0 以减小权重的值，会怎么样呢？
3. 从结论来说，将权重初始值设为 0 不是一个好主意。事实上，将权重初始值设为 0 的话，将无法正确进行学习。
4. 为什么不能将权重初始值设为 0 呢？严格地说，为什么不能将权重初始值设成一样的值呢？
5. 这是因为在误差反向传播法中，所有的权重值都会进行相同的更新。
6. 比如，在 2 层神经网络中，假设第 1 层和第 2 层的权重为 0。这样一来，正向传播时，因为输入层的权重为 0，经过第一个 affine 层后，输出的每个值都是一样的，都是偏置的值，所以第 2 层的神经元中全部输入相同的值。
7. 这意味着，反向传播时第 2 层的权重全部都会进行相同值的更新。因此，权重被更新为相同的值，并拥有了对称的值（重复的值）。这使得神经网络拥有许多不同的权重的意义丧失了，因为最优的权重肯定不会是对称的。
8. 为了防止 “权重均一化”（严格地讲，是为了瓦解权重的对称结构），必须随机生成初始值。

### 2.2 隐藏层的激活值的分布
1. 我们来做一个简单的实验，观察权重初始值是如何影响隐藏层的激活值的分布的。
2. 这里要做的实验是，向一个 5 层神经网络（激活函数使用 sigmoid 函数）传入随机生成的输入数据，用直方图绘制各层激活值的数据分布。
3. 这里假设神经网络有 5 层，每层有 100 个神经元。然后，用高斯分布随机生成 1000 个数据作为输入数据，并把它们传给 5 层神经网络。

#### 2.2.1 梯度消失
1. 首先试验对权重使用标准差为 1 的高斯分布，
    ```py
    w = np.random.randn(node_num, node_num) * 1
    ```
2. 得到 5 层神经网络激活值的分布
    <img src="./images/07.png" width="800" style="display: block; margin: 5px 0 10px;" />
3. 可以看到，各层的激活值呈偏向 0 和 1 的分布，说明在当前标准差较大的权重设定下，仿射层计算震动比较剧烈，导致结果都拥有很大的绝对值。
4. 应为是 sigmoid 函数，所以随着激活值不断地靠近 0 或 1，它的导数的值逐渐接近 0。
5. 因此，偏向 0 和 1 的数据分布会造成反向传播中梯度的值不断变小，最后消失。这个问题称为 **梯度消失**（gradient vanishing）。
6. 层次加深的深度学习中，梯度消失的问题可能会更加严重。当梯度很小以至趋于消失是，梯度下降应该就会很慢甚至停止吧。

#### 2.2.2 “表现力受限”
1. 现在对权重使用标准差为 0.01 的高斯分布，
    ```py
    w = np.random.randn(node_num, node_num) * 0.01
    ```
2. 得到 5 层神经网络激活值的分布
    <img src="./images/08.png" width="800" style="display: block; margin: 5px 0 10px;" />
3. 可以看到，这次各层的激活值呈集中在 0.5 附近的分布。说明在当前标准差较小的权重设定下，仿射层计算震动比较小，导致结果都拥有很小的绝对值。
4. 因为不像刚才的例子那样偏向 0 和 1，所以不会发生梯度消失的问题。但是，激活值的分布有所偏向，说明在表现力上会有很大问题。
5. 为什么这么说呢？因为如果有多个神经元都输出几乎相同的值，那它们就没有存在的意义了。比如在 `Theories\AI\NeuralNetwork\Basic.md` “神经网络基本工作模式的例子” 中介绍的情况，必须要有某些神经元体现出不同的值，才能体现出对关键因素的识别。

#### 2.2.3 Xavier 初始值
1. 接着，我们尝试使用 Xavier Glorot 等人的论文中推荐的权重初始值（俗称“Xavier 初始值”）。现在，在一般的深度学习框架中，Xavier 初始值已被作为标准使用。
2. Xavier 的论文中，为了使各层的激活值呈现出具有相同广度的分布，推导了合适的权重尺度。推导出的结论是，如果前一层的节点数为 `n`，则初始值使用标准差为 `\frac{1}{\sqrt{n}}` 的分布
    ```py
    w = np.random.randn(node_num, node_num) * np.sqrt(node_num)
    ```
3. 使用 Xavier 初始值后，前一层的节点数越多，要设定为目标节点的初始值的权重尺度就越小。
4. 得到 5 层神经网络激活值的分布
    <img src="./images/09.png" width="800" style="display: block; margin: 5px 0 10px;" />
5. 从这个结果可知，越是后面的层，图像变得越歪斜，但是呈现了比之前更有广度的分布。因为各层间传递的数据有适当的广度，所以 sigmoid 函数的表现力不受限制，有望进行高效的学习。

##### `tanh` 函数
1. 上图的分布中，后面的层的分布呈稍微歪斜的形状。如果用 `tanh` 函数（双曲线函数）代替 `sigmoid` 函数，这个稍微歪斜的问题就能得到改善。
2. 实际上，使用 `tanh` 函数后，会呈漂亮的吊钟型分布。`tanh` 函数和 `sigmoid` 函数同是 S 型曲线函数，但 `tanh` 函数是关于原点 $(0, 0)$ 对称的 S 型曲线，而 `sigmoid` 函数是关于 $(x, y)=(0, 0.5)$ 对称的 S 型曲线。
3. 众所周知，用作激活函数的函数最好具有关于原点对称的性质。不懂


## References
* [《深度学习入门》](https://book.douban.com/subject/30270959/)