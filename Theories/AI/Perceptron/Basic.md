# Basic

<!-- TOC -->

- [Basic](#basic)
    - [0. 思想](#0-思想)
    - [1. 感知机是什么](#1-感知机是什么)
    - [2. 用感知机实现简单逻辑电路](#2-用感知机实现简单逻辑电路)
        - [2.1 与门](#21-与门)
        - [2.2 与非门](#22-与非门)
        - [2.3 或门](#23-或门)
    - [3. 感知机的图像表示](#3-感知机的图像表示)
    - [4. 拓展到多维数据](#4-拓展到多维数据)
    - [5. 感知机的局限](#5-感知机的局限)
        - [5.1 线性和非线性](#51-线性和非线性)
    - [6. 多层感知机](#6-多层感知机)
        - [6.1 多层感知机曾经遇到的局限](#61-多层感知机曾经遇到的局限)
    - [7. 从与非门到计算机](#7-从与非门到计算机)
    - [References](#references)

<!-- /TOC -->


## 0. 思想
1. 感知机就像神经元这样基础的单元。
2. 一个复杂的感知系统，也都是有很多个基础的感知单元组成的。
3. 复杂的感知系统接收复杂的输入信号，最终信号也是被分解为基础的单元被基础的感知单元所接收。
4. 使用最简单的神经元叠加可以构建出复杂的大脑，同样使用基础的感知单元也可以构建出高级的人工智能。


## 1. 感知机是什么
1. 感知机接收多个输入信号，输出一个信号。想想生物的情况，也是接收信息并做出反应。
2. 感知机的信号只有1/0两种取值。对生物来说，在更高层上可能会接收所谓的复杂信号，但其实分解到底层神经元上，也是很简单的电信号。
3. 一个输入信号值乘以它的权重$w$，就是神经元节点接收到的信号实际值。显然对生物来说，不同的信息输入有不同的重要性。
    <img src="./images/01.png" style="display: block" width="400" />
4. 神经元会计算传送过来的信号的总和，只有当这个总和超过了某个界限值时，才会输出 1。这也称为“神经元被激活”。这里将这个界限值称为阈值，用符号$θ$表示。对生物来说，某种刺激太弱也不会做出相应的反应。
    * $w1x2 + w2x2 <= θ$，$y$ 输出 $0$
    * $w1x2 + w2x2 > θ$， $y$ 输出 $1$
5. 后续使用中，将使用偏置$b$来代替阈值$θ$，变形如下：
    * $b + w1x2 + w2x2 <= 0$，$y$ 输出 $0$
    * $b + w1x2 + w2x2 > 0$， $y$ 输出 $1$


## 2. 用感知机实现简单逻辑电路
### 2.1 与门
1. x1、x2 的输入和对应的 y 输入应如下：
    x1 | x2 | y
    --|--|--
    0 | 0 | 0
    1 | 0 | 0
    0 | 1 | 0
    1 | 1 | 1
2. 要用感知机实现，就需要设定合适的偏置和权重，使得上表前三行的 $x1$、$x2$ 的输入的计算结果小于等于$0$，第四行输入的计算结果大于$0$。
2. python 实现如下
    ```py
    import numpy as np

    def AND(x1, x2):
        x = np.array([x1, x2])
        w = np.array([0.5, 0.5]) # 设定权重
        b = -0.7 # 设定偏置
        tmp = np.sum(w*x) + b
        if tmp <= 0:
            return 0
        else:
            return 1
    ```

### 2.2 与非门
1. 真值表
    x1 | x2 | y
    --|--|--
    0 | 0 | 1
    1 | 0 | 1
    0 | 1 | 1
    1 | 1 | 0
2. python 实现
    ```py
    def NAND(x1, x2):
        x = np.array([x1, x2])
        w = np.array([-0.5, -0.5])
        b = 0.7
        tmp = np.sum(w*x) + b
        if tmp <= 0:
            return 0
        else:
            return 1
    ```

### 2.3 或门
1. python 实现
    ```py
    def OR(x1, x2):
        x = np.array([x1, x2])
        w = np.array([0.5, 0.5])
        b = -0.2
        tmp = np.sum(w*x) + b
        if tmp <= 0:
            return 0
        else:
            return 1
    ```


## 3. 感知机的图像表示
1. 从上面的描述可以看出，偏置和权重作为设定的参数，$x1$ 和 $x2$ 作为实际的变量，感知机可以用直角坐标系加上一条直线来表示。例如下面$-0.5 + x1 + x2$的或门实现（偏置为-0.5，权重为1的感知机）。直线的方程为 $-0.5 + x1 + x2 = 0$，三角和圆形代表或门的四个输入值，即 $(1, 1)$ $(1, 0)$ $(0, 1)$ $(0,0])
    <img src="./images/or.png" style="display: block" width="400" />
2. 给定参数的感知机，它的图形意义就是：在 $x1$、$x2$ 直角坐标系里画出一条直线，这个直线上的每一点和 $b + w1x1 + w2x2 = 0$ 的 $x1$、$x2$ 的取值一一对应。也就是说，这条直线就是根据 $b + w1x1 + w2x2 = 0$ 画出来的。
3. 考虑直线的左侧空间，对于任意一点来说，都可以说是直线上的一点向左或向下移动后到达的，都是一个值不变另一个值减小，因此上面式子的结果就会小于零。例如左侧的 $(0, 0)$ 点，就可以是直线上的 $(0, 1)$ 点通过 $x1$ 不变 $x2$ 减小来到达，或者通过直线上的 $(1, 0)$ 点通过 $x1$ 不变 $x1$ 减小来到达同理。总之不管是那种移动方式，上面式子的结果都会小于0。
4. 也就是说，直线一侧的坐标值求得结果都是负数，而另一侧求得的结果都是正数。
5. 因此在上图中，因为选定了 1、1、0.5 作为权重和偏置而画出图中的直线，就使得输入$(0,0)$在条直线左侧而输入$(0, 1)(1, 0)(1, 1)$在直线右侧，就可以以此参数实现或门感知机。这个直线的方程就是该或门感知机的数学表达式。


## 4. 拓展到多维数据
1. 上述感知机实现中确定分界线，被称为**决策分界**。上面的决策分界就是在二维的数据平面中划出一条直线。
2. 当数据的维度是3维的时候，决策分界就是划出一个平面；当数据的维度是n维时，决策分界就是一个 n-1 维的超平面。

## 5. 感知机的局限
1. 考虑异或门的输入和输出，要求在坐标轴中划出一条直线，使得两个三角形在一侧（表达式大于零）两个圆形在另一侧（表达式小于零）
    <img src="./images/xor.png" style="display: block" width="400" />
2. 显然是画不出这样的直线的，也就是说异或问题是**线性不可分**的。

### 5.1 线性和非线性
1. 感知机的局限性就在于它只能表示由一条直线分割的空间。下图这样弯曲的曲线无法用感知机表示。
    <img src="./images/02.png" style="display: block" width="600" />
2. 这样的曲线分割而成的空间称为非线性空间，由直线分割而成的空间称为线性空间。
3. 即使对于三维数据或者更高维度的数据，这种局限依然存在，决策分界依然只能实现平面和超平面，而不能发生弯曲。


## 6. 多层感知机
1. 感知机不能表示异或门让人深感遗憾，但也无需悲观。实际上，感知机的绝妙之处在于它可以“叠加层”。
2. 通过叠加层实现多层感知机（multi-layered perceptron）。
    <img src="./images/03.png" style="display: block" width="600" />
3. 通过叠加层感知机实现异或门
    <img src="./images/04.png" style="display: block" width="600" />  
    <img src="./images/05.png" style="display: block" width="600" />
    ```py
    def XOR(x1, x2):
        s1 = NAND(x1, x2)
        s2 = OR(x1, x2)
        y = AND(s1, s2)
        return y
    ```
4. 通过叠加三个感知机，最终形成的函数不再是线性的，而是单调性是会变化的，也就是说会弯曲的。因此就可以解决异或门这样线性不可分的问题。
5. 单层感知机的决策分界本身是一个线性方程，虽然最后用一个激活函数输出了0或者1，但负责分类的还是线性方程。而多层感知机情况，`s1` 和 `s2` 的计算已经是经过激活函数处理过了，已经加入了非线性特性。
6. 如果只是叠加层而不适用激活函数，线性不可分最终还是无法解决，因为没有激活函数最终的决策分界还是线性的。
7. 要注意的一点是，其实最后一步 `AND` 计算中的决策分界函数本身仍然是一个线性函数，但最终却能进行非线性的分类。激活函数假如非线性因素的大致原理会在 `../NeuralNetwork/Basic.md` 中说明。

### 6.1 多层感知机曾经遇到的局限
1. Minsky 在1969年出版了一本叫《Perceptron》的书，里面用详细的数学证明了感知器的弱点，尤其是感知器对 XOR 这样的简单分类任务都无法解决。
2. Minsky 认为，如果将计算层增加到两层，计算量则过大，而且没有有效的学习算法。所以，他认为研究更深层的网络是没有价值的。神经网络的研究因此陷入了冰河期。
3. 直到1986年，Rumelhar 和 Hinton 等人提出了**反向传播**（Backpropagation，BP）算法，解决了两层神经网络所需要的复杂计算量问题，从而带动了业界使用两层神经网络研究的热潮。


## 7. 从与非门到计算机
1. 多层感知机可以实现比之前见到的电路更复杂的电路。比如，进行加法运算的加法器也可以用感知机实现。此外，将二进制转换为十进制的编码器、满足某些条件就输出 1 的电路（用于等价检验的电路）等也可以用感知机表示。
2. 实际上，使用感知机甚至可以表示计算机！
3. 计算机是处理信息的机器。向计算机中输入一些信息后，它会按照某种既定的方法进行处理，然后输出结果。所谓“按照某种既定的方法进行处理”是指，计算机和感知机一样，也有输入和输出，会按照某个既定的规则进行计算。
4. 人们一般会认为计算机内部进行的处理非常复杂，而令人惊讶的是，实际上只需要通过与非门的组合，就能再现计算机进行的处理。
5. 这一令人吃惊的事实说明了什么呢？说明使用感知机也可以表示计算机。前面也介绍了，与非门可以使用感知机实现。也就是说，如果通过组合与非门可以实现计算机的话，那么通过组合感知机也可以表示计算机（感知机的组合可以通过叠加了多层的单层感知机来表示）。
6. 综上，多层感知机能够进行复杂的表示，甚至可以构建计算机。那么，什么构造的感知机才能表示计算机呢？层级多深才可以构建计算机呢？
7. 理论上可以说 2 层感知机就能构建计算机。这是因为，已有研究证明，2 层感知机（严格地说是激活函数使用了非线性的 sigmoid 函数的感知机）可以表示任意函数。
8. 但是，使用 2 层感知机的构造，通过设定合适的权重来构建计算机是一件非常累人的事情。
9. 实际上，在用与非门等低层的元件构建计算机的情况下，分阶段地制作所需的零件（模块）会比较自然，即先实现与门和或门，然后实现半加器和全加器，接着实现算数逻辑单元（ALU），然后实现 CPU。因此，通过感知机表示计算机时，使用叠加了多层的构造来实现是比较自然的流程。



## References
* [《深度学习入门：基于Python的理论与实现》](https://book.douban.com/subject/30270959/)
* [感知机与多层网络，解决异或问题可视化](https://blog.csdn.net/sinat_28685897/article/details/85241977)