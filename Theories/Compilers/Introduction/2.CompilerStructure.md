# The Structure of a Compiler


<!-- TOC -->

- [The Structure of a Compiler](#the-structure-of-a-compiler)
    - [Summary](#summary)
    - [词法分析（Lexical Analysis）](#词法分析lexical-analysis)
    - [语法分析（Syntax Analysis）](#语法分析syntax-analysis)
        - [语法和语义的区别](#语法和语义的区别)
    - [语义分析（Semantic Analysis）](#语义分析semantic-analysis)
    - [Intermediate Code Generation](#intermediate-code-generation)
    - [Code Optimization](#code-optimization)
    - [Code Generation](#code-generation)
    - [References](#references)

<!-- /TOC -->


## Summary
1. Up to this point we have treated a compiler as a single box that maps a source program into a semantically equivalent target program. If we open up this box a little, we see that there are two parts to this mapping: analysis and synthesis.
2. The *analysis* part breaks up the source program into constituent pieces and imposes a grammatical structure on them. It then uses this structure to create an intermediate representation of the source program.
3. If the analysis part detects that the source program is either syntactically ill formed or semantically unsound, then it must provide informative messages, so the user can take corrective action. 
4. The analysis part also collects information about the source program and stores it in a data structure called a *symbol table*, which is passed along with the intermediate representation to the synthesis part.
5. The *synthesis* part constructs the desired target program from the intermediate representation and the information in the symbol table. 
6. The analysis part is often called the *front end* of the compiler; the synthesis part is the *back end*.
7. If we examine the compilation process in more detail, we see that it operates as a sequence of phases, each of which transforms one representation of the source program to another. 
8. A typical decomposition of a compiler into phases is shown below
    <img src="./images/06.png" width="400" style="display: block; margin: 5px 0 10px;" />
9. In practice, several phases may be grouped together, and the intermediate representations between the grouped phases need not be constructed explicitly. 
10. The symbol table, which stores information about the entire source program, is used by all phases of the compiler.
11. Some compilers have a machine-independent optimization phase between the front end and the back end. The purpose of this optimization phase is to perform transformations on the intermediate representation, so that the back end can produce a better target program than it would have otherwise produced from an unoptimized intermediate representation. 
12. Since optimization is optional, one or the other of the two optimization phases shown above may
be missing.


## 词法分析（Lexical Analysis）
1. The frst phase of a compiler is called *lexical analysis* or *scanning*。 扫描识别出源码字符流中那些事有意义的字符组合。
2. The lexical analyzer reads the stream of characters making up the source program and groups the characters into meaningful sequences called *lexemes*。把字符流识别为一个个对程序来说有意义的词位，这里的刺猬 lexeme 大概就是源码中不能插入空格的一个或一段字符。
3. For each lexeme, the lexical analyzer produces as output a *token* of the form
    $$\langle token-name, attribute-value \rangle$$ 
    that it passes on to the subsequent phase, syntax analysis。token 是对源码中的 lexeme 分析结果。
4. In the token, the frst component *token-name* is an abstract symbol that is used during syntax
analysis, and the second component *attribute-value* points to an entry in the symbol table for this token. 
5. Information from the symbol-table entry is needed for semantic analysis and code generation.
6. For example, suppose a source program contains the assignment statement
    ```
    position = initial + rate * 60
    ```
7. The characters in this assignment could be grouped into the following 7 lexemes and mapped into the following 7 tokens passed on to the syntax analyzer (Blanks separating the lexemes would be discarded by the lexical analyzer.):
    1. `position` is a lexeme that would be mapped into a token $\langle id, 1 \rangle$, where `id` is an abstract symbol standing for *identifer* and `1` points to the symbol-table entry for `position`. The symbol-table entry for an identifer holds information about the identifer, such as its name and type.
    2. The assignment symbol `=` is a lexeme that is mapped into the token $\langle = \rangle$. Since this token needs no attribute-value, we have omitted the second component. We could have used any abstract symbol such as `assign` for the token-name, but for notational convenience we have chosen to use the lexeme itself as the name of the abstract symbol.
    3. `initial` is a lexeme that is mapped into the token $\langle id, 2 \rangle$, where `2` points
    to the symbol-table entry for initial.
    4. `+` is a lexeme that is mapped into the token $\langle + \rangle$.
    5. `rate` is a lexeme that is mapped into the token $\langle id, 3 \rangle$, where `3` points to
    the symbol-table entry for rate.
    6. `*` is a lexeme that is mapped into the token $\langle * \rangle$.
    7. `60` is a lexeme that is mapped into the token $\langle 60 \rangle$.
8. 下图包括了对这行代码进行词法分析的结果以及之后的处理步骤
    <img src="./images/07.png" width="500" style="display: block; margin: 5px 0 10px;" />


## 语法分析（Syntax Analysis）
1. The second phase of the compiler is *syntax analysis* or *parsing*。上一步识别除了单词及其含义，这一步就要识别出单词组成的一句话是要干什么。
2. The parser uses the frst components of the tokens produced by the lexical analyzer to create
a tree-like intermediate representation that depicts the grammatical structure of the token stream. 
3. A typical representation is a *syntax tree* in which each interior node represents an operation and the children of the node represent the arguments of the operation. 
4. A syntax tree for the token stream is shown as the output of the syntactic analyzer in the figure above.
5. This tree shows the order in which the operations in the assignment 
    ```
    position = initial + rate * 60
    ```
    are to be performed. 
6. The subsequent phases of the compiler use the grammatical structure to help analyze the source program and generate the target program.

### 语法和语义的区别
1. 前者关心一句话的语言法则，后者关心这句话的意思是什么。
2. 例如说 “我吃了饭”，这句话语法和语义都没问题；但如果说 “饭吃了我”，这句话语法上也没问题，很正确的主谓宾结构，但语义就是有问题的；再比如说 “我吃了非常的”，那就直接在语法上就有问题了。
3. 在代码中，`console.log(n;` 是属于语法错误；如果没有声明 `n`，但却执行 `console.log(n)`，那就是语义错误。
4. 也就是说，语法分析只看这句话本身；但是语义分析就要结合上下文。


## 语义分析（Semantic Analysis）
1. The *semantic analyzer* uses the syntax tree and the information in the symbol table to check the source program for semantic consistency with the language defnition. 
2. It also gathers type information and saves it in either the syntax tree or the symbol table, for subsequent use during intermediate-code generation.
3. An important part of semantic analysis is *type checking*, where the compiler checks that each operator has matching operands. For example, many programming language definitions require an array index to be an integer; the compiler must report an error if a ﬂoating-point number is used to index an array
    ```cpp
    void print_int (int n) {
        printf("%d\n", n);
    }

    float f = 3.14;

    print_int(f); // 这一行代码本身没有语法问题，但结合上下文，显然语义是错误的
    ```
4. The language specifcation may permit some type conversions called *coercions*. For example, a binary arithmetic operator may be applied to either a pair of integers or to a pair of ﬂoating-point numbers. If the operator is applied to a ﬂoating-point number and an integer, the compiler may convert or coerce the integer into a ﬂoating-point number.
5. 在上面例子中的 `rate * 60` 就是这种情况，所以语义分析阶段就会把 `60` 强制转换为浮点数。在上面流程图的语义分析阶段的输出中，可以看出对 `60` 进行了 `inttofloat` 的操作。


## Intermediate Code Generation
1. In the process of translating a source program into target code, a compiler may construct one or more intermediate representations, which can have a variety of forms. 
2. Syntax trees are a form of intermediate representation; they are commonly used during syntax and semantic analysis.
3. After syntax and semantic analysis of the source program, many compilers generate an explicit low-level or machine-like intermediate representation, which we can think of as a program for an abstract machine. 
4. This intermediate representation should have two important properties: it should be easy to
produce and it should be easy to translate into the target machine.


## Code Optimization
1. The machine-independent code-optimization phase attempts to improve the intermediate code so that better target code will result. 
2. Usually better means faster, but other objectives may be desired, such as shorter code, or target code that consumes less power. 


## Code Generation
1. The code generator takes as input an intermediate representation of the source program and maps it into the target language. 
2. If the target language is machine code, registers or memory locations are selected for each of the variables used by the program. 
3. Then, the intermediate instructions are translated into sequences of machine instructions that perform the same task. 
4. A crucial aspect of code generation is the judicious assignment of registers to hold variables.


## References
* [*Compilers*](https://book.douban.com/subject/1866231/)