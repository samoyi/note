# The Structure of a Compiler


<!-- TOC -->

- [The Structure of a Compiler](#the-structure-of-a-compiler)
    - [Summary](#summary)
    - [词法分析（Lexical Analysis）](#词法分析lexical-analysis)
    - [语法分析（Syntax Analysis）](#语法分析syntax-analysis)
    - [References](#references)

<!-- /TOC -->


## Summary
1. Up to this point we have treated a compiler as a single box that maps a source program into a semantically equivalent target program. If we open up this box a little, we see that there are two parts to this mapping: analysis and synthesis.
2. The *analysis* part breaks up the source program into constituent pieces and imposes a grammatical structure on them. It then uses this structure to create an intermediate representation of the source program.
3. If the analysis part detects that the source program is either syntactically ill formed or semantically unsound, then it must provide informative messages, so the user can take corrective action. 
4. The analysis part also collects information about the source program and stores it in a data structure called a *symbol table*, which is passed along with the intermediate representation to the synthesis part.
5. The *synthesis* part constructs the desired target program from the intermediate representation and the information in the symbol table. 
6. The analysis part is often called the *front end* of the compiler; the synthesis part is the *back end*.
7. If we examine the compilation process in more detail, we see that it operates as a sequence of phases, each of which transforms one representation of the source program to another. 
8. A typical decomposition of a compiler into phases is shown below
    <img src="./images/06.png" width="400" style="display: block; margin: 5px 0 10px;" />
9. In practice, several phases may be grouped together, and the intermediate representations between the grouped phases need not be constructed explicitly. 
10. The symbol table, which stores information about the entire source program, is used by all phases of the compiler.
11. Some compilers have a machine-independent optimization phase between the front end and the back end. The purpose of this optimization phase is to perform transformations on the intermediate representation, so that the back end can produce a better target program than it would have otherwise produced from an unoptimized intermediate representation. 
12. Since optimization is optional, one or the other of the two optimization phases shown above may
be missing.


## 词法分析（Lexical Analysis）
1. The frst phase of a compiler is called *lexical analysis* or *scanning*。 扫描识别出源码字符流中那些事有意义的字符组合。
2. The lexical analyzer reads the stream of characters making up the source program and groups the characters into meaningful sequences called *lexemes*。把字符流识别为一个个对程序来说有意义的词位，这里的刺猬 lexeme 大概就是源码中不能插入空格的一个或一段字符。
3. For each lexeme, the lexical analyzer produces as output a *token* of the form
    $$\langle token-name, attribute-value \rangle$$ 
    that it passes on to the subsequent phase, syntax analysis。token 是对源码中的 lexeme 分析结果。
4. In the token, the frst component *token-name* is an abstract symbol that is used during syntax
analysis, and the second component *attribute-value* points to an entry in the symbol table for this token. 
5. Information from the symbol-table entry is needed for semantic analysis and code generation.
6. For example, suppose a source program contains the assignment statement
    ```
    position = initial + rate * 60
    ```
7. The characters in this assignment could be grouped into the following 7 lexemes and mapped into the following 7 tokens passed on to the syntax analyzer (Blanks separating the lexemes would be discarded by the lexical analyzer.):
    1. `position` is a lexeme that would be mapped into a token $\langle id, 1 \rangle$, where `id` is an abstract symbol standing for *identifer* and `1` points to the symbol-table entry for `position`. The symbol-table entry for an identifer holds information about the identifer, such as its name and type.
    2. The assignment symbol `=` is a lexeme that is mapped into the token $\langle = \rangle$. Since this token needs no attribute-value, we have omitted the second component. We could have used any abstract symbol such as `assign` for the token-name, but for notational convenience we have chosen to use the lexeme itself as the name of the abstract symbol.
    3. `initial` is a lexeme that is mapped into the token $\langle id, 2 \rangle$, where `2` points
    to the symbol-table entry for initial.
    4. `+` is a lexeme that is mapped into the token $\langle + \rangle$.
    5. `rate` is a lexeme that is mapped into the token $\langle id, 3 \rangle$, where `3` points to
    the symbol-table entry for rate.
    6. `*` is a lexeme that is mapped into the token $\langle * \rangle$.
    7. `60` is a lexeme that is mapped into the token $\langle 60 \rangle$.
8. 下图包括了对这行代码进行词法分析的结果以及之后的处理步骤
    <img src="./images/07.png" width="500" style="display: block; margin: 5px 0 10px;" />


## 语法分析（Syntax Analysis）
1. The second phase of the compiler is *syntax analysis* or *parsing*。上一步识别除了单词及其含义，这一步就要识别出单词组成的一句话是要干什么。
2. The parser uses the frst components of the tokens produced by the lexical analyzer to create
a tree-like intermediate representation that depicts the grammatical structure of the token stream. 
3. A typical representation is a *syntax tree* in which each interior node represents an operation and the children of the node represent the arguments of the operation. 
4. A syntax tree for the token stream is shown as the output of the syntactic analyzer in the figure above.
5. This tree shows the order in which the operations in the assignment 
    ```
    position = initial + rate * 60
    ```
    are to be performed. 
6. The subsequent phases of the compiler use the grammatical structure to help analyze the source program and generate the target program.







## References
* [*Compilers*](https://book.douban.com/subject/1866231/)